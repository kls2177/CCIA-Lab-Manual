# Lab exercise 1: Understanding the recent past {#lab1}

_Last update: `r system("git log -1 --format=\"%ad (%h)\" -- 03-Lab1.Rmd", intern = TRUE)`_

```{r setup, include=FALSE}
library(reticulate)
conda <- ifelse(file.exists("/opt/conda/bin/conda"), "/opt/conda/bin/conda", "/data/home-ext/miniconda3/bin/conda")
use_condaenv("man_ccia", conda = conda, required = TRUE)
source("R/deco_hook.R")
```

```{python py_setup, include=FALSE}
import matplotlib as mpl
mpl.use("agg") # Needed for the book only
mpl.rc('font', size = 12)
from matplotlib import pyplot as plt
plt.switch_backend('agg') # Might be overkill
import numpy as np
import pandas as pd
pd.set_option('display.max_columns', 10)
import scipy.stats as stats
```


```{bash get_csvs, include=FALSE}
wget https://gitlab.com/ConorIA/shell-scripts/raw/master/eccc/eccc
chmod +x eccc
./eccc -y 1981:2010 -s 5051 -g
./eccc -y 2000:2010 -s 31688 -g
```

One of the first steps of a climate change impact assessment (CCIA) is to establish a climatological baseline  for the climate variable of interest (either an exposure unit or the climate variable most directly linked to the exposure unit). 

An __exposure unit__ is an element or variable that is directly or indirectly affected by the changes in climate. In this exercise you will acquire Canadian climate data for Toronto and perform an analysis of an exposure unit that will be assigned to you. Refer to the Appendix (\@ref(appendix)) for a list of some example exposure units. 

What do we mean by baseline? A baseline period is needed to define the observed climate. This observed climate information is combined with GCM output of climate change to determine the climate change impact for a given future climate scenario (e.g. Representative Concentration Pathway (RCP)). When using climate model output, the baseline also serves as the reference period from which the modelled future change in climate is calculated. Future climate change is defined by comparing the years in the baseline period with the similar number of years in the future for a given future climate scenario.

Environment and Climate Change Canada (ECCC) makes data available over an internet portal. You can [visit this page](http://climate.weather.gc.ca/), and download data manually, but that is a _very_ tedious process. In this lab, I will present you with two options for downloading Canadian climate data: the command-line, and via an R package. 

## Getting the data

### Option 1: On the command line

ECCC makes data available over an [FTP site](ftp://client_climate@ftp.tor.ec.gc.ca/Pub/Get_More_Data_Plus_de_donnees/), and gives instructions for downloading data manually via `bash` and `wget`. You can find instructions for using the command line to download data [here](ftp://client_climate@ftp.tor.ec.gc.ca/Pub/Get_More_Data_Plus_de_donnees/Readme.txt).

#### A scripted solution

For convenience, I have written a script, called `eccc` to perform this downloading. You can get the latest version of this script from [GitLab](https://gitlab.com/ConorIA/shell-scripts/raw/master/eccc/eccc). In fact, this is a great opportunity to test if your `wget` installation is working correctly. Fire up a terminal, and download the script using `wget`.

```{bash, eval=FALSE, deco=list(label="Shell", bc="#000000", tc="#ffffff", icon=list(style="fas", name="terminal"))}
wget https://gitlab.com/ConorIA/shell-scripts/raw/master/eccc/eccc
```

The above command should provide verbose download progress information, which I have omitted here. Once the command has run, you should find a file called `eccc` in your current directory. To get help using `eccc`, pass the `-h` flag to the script. 

```{bash, deco=list(label="Shell", bc="#000000", tc="#ffffff", icon=list(style="fas", name="terminal"))}
./eccc -h
```

```{block, type='rmdtip'}
Note, if you are on Linux or Mac, and get a "permission denied" error message from the above command, you will need to set the script as executable (also know as "setting the executable bit") by changing the file permissions with `chmod`, e.g.

<div class="decocode"><div style="background-color:#000000"><p><span style="font-size:90%;color:#ffffff"><i class="fas fa-terminal"></i> <b>Shell</b></span></p>
    chmod +x eccc
</div></div>

If for some reason you can't use `chmod` you can the skip setting the permissions by explicitly asking `bash` (which is executable) to run the script. To do this, prepend each call to the script with `bash`, e.g. `bash eccc -h`.
```

The `-h` flag tells `eccc` to print help information about using the script. Each argument (or flag) is explained in the output. To download daily data for Toronto, for instance, you can run the script like this: 

```{bash, eval=FALSE, deco=list(label="Shell", bc="#000000", tc="#ffffff", icon=list(style="fas", name="terminal"))}
./eccc -s 5051 -y 1981:2010 -g
```

This will download the individual year-by-year _csv_ files for daily data at Toronto (station 5051), automatically cropping the metadata from the beginning of each file, and then "gluing" them all together in a single file. In this case. That file is called "_`r list.files(pattern = "5051.*csv")`_".

#### Cleaning the data in Python

Now that we have the data that we need, we need to start working with it. Fire up your installation of Python, and follow along with the following commands. 

First, let's import the libraries we are going to need to manipulate our data. 

```{python, eval=FALSE, deco=list()}
import numpy as np
import pandas as pd
```

Now read the _csv_ files into Python. 

```{python, deco=list()}
tor = pd.read_csv("5051-daily.csv")
```

Let's take a look at what our columns are named. 

```{python, deco=list()}
print(tor.columns)
```

Hmm, some of those are are a little cumbersome. Let's rename the columns we are going to use and then select only those columns. 

```{python, deco=list()}
tor = tor.rename(columns={'Date/Time': 'Date', 'Max Temp (°C)': 'MaxTemp', 'Min Temp (°C)': 'MinTemp', 'Mean Temp (°C)': 'MeanTemp', 'Total Precip (mm)': 'TotalPrecip'})
tor = tor[['Date', 'MaxTemp', 'MinTemp', 'MeanTemp', 'TotalPrecip']]
```

Great. Let's take a look at what we've got. 

```{python, deco=list()}
print(tor.head())
```
```{python, deco=list()}
print(tor.tail())
```

Uhh ohh! It looks like we are missing all of our temperature data at the end of our _csv_ file. We can test this theory by using an enumerator. The following will tell us the index at which all three of our temperature variables of interest are missing for the first time. 
```{python, deco=list()}
print(next(i for i, x in enumerate(tor.loc[:, 'MaxTemp':'MeanTemp'].isnull().all(axis=1)) if x) - 1)
```

Let's take a look at the context around that index. 

```{python, deco=list()}
print(tor[8211:8221])
```

It looks like we're missing data as of July 2003. Indeed, in 2003 the "Toronto" station was renamed "Toronto City" and re-coded. Since that date, the daily data is available under station code 31688. 

We'll have to return to `bash` for a moment to get the data that we're missing. Let's grab the data for the new station code from 2000 to 2010. 

```{bash, eval=FALSE, deco=list(label="Shell", bc="#000000", tc="#ffffff", icon=list(style="fas", name="terminal"))}
./eccc -y 2000:2010 -s 31688 -g
```

Now let's return to Python. 

```{python, deco=list()}
tor2 = pd.read_csv("31688-daily.csv")
tor2 = tor2.rename(columns={'Date/Time': 'Date', 'Max Temp (°C)': 'MaxTemp', 'Min Temp (°C)': 'MinTemp', 'Mean Temp (°C)': 'MeanTemp', 'Total Precip (mm)': 'TotalPrecip'})
tor2 = tor2[['Date', 'MaxTemp', 'MinTemp', 'MeanTemp', 'TotalPrecip']]
```

We can check the head and the tail of this data too. 

```{python, deco=list()}
print(tor2.head())
```
```{python, deco=list()}
print(tor2.tail())
```

As expected, we're missing data at the beginning of the file (before 2003). We can use a slightly modified version of our iterator from earlier. This time, we'll check for the first row for which any of the data is present. 

```{python, deco=list()}
print(next(i for i, x in enumerate(tor2.loc[:, 'MaxTemp':'MeanTemp'].notnull().any(axis=1)) if x) - 1)
```

We'll take a look at that in context again. 

```{python, deco=list()}
print(tor2[880:890])
```

It looks like our data starts as of June 04, 2002. 

OK, so we know that we have data at the old station until May 30, 2002. Likewise, we have some data at the new station in May 2002. Let's take a look at the overlap and see if we can merge these files without issue. 

```{python, deco=list()}
print(tor[(tor.Date >= "2003-06-25") & (tor.Date <= "2003-07-05")])
```
```{python, deco=list()}
print(tor2[(tor2.Date >= "2003-06-25") & (tor2.Date <= "2003-07-05")])
```

The data on the overlapping days is virtually identical between the two station codes, so we can be confident that merging these two data sets won't lead to a sudden temperature bump. Let's append the relevant section of `tor2` to `tor`.

```{python, deco=list()}
tor = tor[tor.Date < "2003-07-01"].append(tor2[tor2.Date >= "2003-07-01"])
```

Now we can make sure that we have a full data set from January 1981 to December 2010. 

```{python, deco=list()}
print(tor.head())
```
```{python, deco=list()}
print(tor.tail())
```

```{bash cleanup, include=FALSE}
rm eccc* *.csv
```

Save your new data set to _csv_ by:

```{python, deco=list()}
tor.to_csv("tor.csv")
```

### Option 2: Using the **canadaHCD** package in R

```{block, type='rmddisclaimer'}
The commands in this section, should (in theory), work in Jupyter Notebook, however, I have experienced constant kernel crashes when attempting. You may have to use a different program, such as Spyder, or use the Python shell directly. 
```

For those of us who work often in R, the **canadaHCD** package [@R-canadaHCD] is the first stop for Canadian climate data. We can take advantage of this package in Python too, thanks to the **rpy2** Python module. We will also use an expansion pack that I have written based on **canadaHCD**, called **canadaHCDx** [@R-canadaHCDx]. Of course, you are free to run any of the R commands in the code below directly in R.

[//]: # (It seems (understandably), that calling rpy2 through reticulate causes all sorts of trouble)

```{block, type='rmddisclaimer'}
In the interest of full disclosure, it should be noted that your output might look slightly different to what you see below. This book was written in R. As you might imagine, it is not possible to run R via Python via R! I have, therefore, provided the code below in the context of Python to R, but am using R "under the hood" to generate the data. 
```

First we need to import our Python libraries.

```{python, eval=FALSE, deco=list()}
import pandas as pd
from rpy2.robjects import r, pandas2ri
```

We now have an object in Python called `r`, that serves as an interface to R. You can pass code to R using `r('your code goes here')`. 

```{python, eval=FALSE, deco=list()}
print(r('R.version.string'))
```
```{r, include=FALSE}
rver <- R.version.string
```
```{python, echo=FALSE}
print(r.rver)
```

In R, we load packages using the `library()` function. You can load a package into your `rpy2` R environment like this:

```{python, eval=FALSE, deco=list()}
r('library(canadaHCDx)')
```

You may see some errors about masking. Both `canadaHCD` and `canadaHCDx` include a `find_station()` function to search for available station data. The more advanced 'x' version masks the former. 

```{python, eval=FALSE, deco=list()}
print(r('find_station("Toronto")'))
```
```{r, include=FALSE}
search <- canadaHCD::find_station("Toronto")
```
```{python, echo = FALSE}
print(r.search)
```

Depending on the platform that you are using, this table might be hard to read. Jupyter Notebook maintains the format as a `R/rpy2 DataFrame` object that abbreviates all the columns. You can convert it into a Python pandas using the `pandas2ri.ri2py()` method. 

```{python, eval=FALSE, deco=list()}
search = pandas2ri.ri2py(search)
```

You can also automatically convert all subsequent R objects to Python by running `pandas2ri.activate()`.

So, we have a _very_ long list of stations, but we have no idea about the kinds of data that are available. **canadaHCDx** includes some more advanced search options.

```{python, eval=FALSE, deco=list()}
r('find_station("Toronto", baseline = 1981:2010, type = "daily")')
```
```{r, include=FALSE}
search <- canadaHCDx::find_station("Toronto", baseline = 1981:2010, type = "daily", assume_yes = TRUE)
```
```{python, echo=FALSE}
print(r.search)
```

It looks like Toronto (5051) has all the data we need. Let's download it.

```{python, eval=FALSE, deco=list()}
print(r('tor <- hcd_daily(5051, 1981:2010, progress = FALSE)').head())
```
```{r, include=FALSE}
tor <- canadaHCD::hcd_daily(5051, 1981:2010, progress = FALSE)
```
```{python, echo=FALSE}
print(r.tor.head())
```

In the above cell, we saved the data into an object on the R "side". We can pull the object into Python via assignment. 

```{python, eval=FALSE, deco=list()}
tor = r('tor')
print(tor.head())

```
```{python, echo=FALSE}
tor = r.tor
print(tor.head())
```

You may encounter that some of the columns become corrupted. The most important among these is the data column. If you find that you have a series of numbers instead of dates, you can easily overwrite the column by:

```{python, deco=list()}
tor['Date'] = pd.date_range(start="1981-01-01", end="2010-12-31")
print(tor.head())
```

It looks like there is something wrong with the `MaxGustDir` and `MaxGustSpeed` columns, but we won't be using them for anything, so we can safely ignore them. Indeed, let's drop the columns that aren't of interest to us. 

```{python, deco=list()}
tor = tor[['Station', 'Date', 'MaxTemp', 'MinTemp', 'MeanTemp', 'TotalPrecip']]
```

Let's check the end of our data. 

```{python, deco=list()}
print(tor.tail())
```

Uhh ohh! It looks like there are a lot of missing temperature values at the end of the data set. Let's look for another station, within 1 km of Toronto that will give us more data. 

```{r, include=FALSE}
search <- canadaHCDx::find_station(target = 5051, dist = 0:1)
```
```{python, eval=FALSE, deco=list()}
r('find_station(target = 5051, dist = 0:1)')
```
```{python, echo=FALSE}
print(r.search)
```

It seems that there was a station code change at Toronto in 2003. The "Toronto" station, 5051, became "Toronto City", 31688. These are co-located. These data sets can be easily merged between 2002 and 2003. 


```{python, eval=FALSE, deco=list()}
t1 = r('hcd_daily(5051, 1981:2002, progress = FALSE)')
t2 = r('hcd_daily(31688, 2003:2010, progress = FALSE)')
```
```{r, include=FALSE}
t1 <- canadaHCD::hcd_daily(5051, 1981:2002, progress = FALSE)
t2 <- canadaHCD::hcd_daily(31688, 2003:2010, progress = FALSE)
```
```{python, include=FALSE}
t1 = r.t1
t2 = r.t2
```

Merge the tables using the pd.append() method.

```{python, deco=list()}
tor = t1.append(t2)
```

Now let's clean this up a little.

```{python, deco=list()}
tor['Date'] = pd.date_range(start="1981-01-01", end="2010-12-31")
tor = tor[['Station', 'Date', 'MaxTemp', 'MinTemp', 'MeanTemp', 'TotalPrecip']]
print(tor.head())
```

```{python, deco=list()}
print(tor.tail())
```

You can save your new data set to _csv_ by:

```{python, eval=FALSE, deco=list()}
tor.to_csv("tor.csv")
```

There you have it! We just downloaded 30 years of data from Environment Canada in Python via R!

## Analyzing the data

Now let's take a look at our data. We will require some additional libraries.

```{python, eval=FALSE, deco=list()}
import matplotlib as mpl
mpl.rc('font', size = 12)
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
import scipy.stats as stats
```

As we mentioned in the introduction, an exposure unit is often the "unit" of our analysis when we want to perform an impact assessment. In this section, we'll calculate two exposure units, starting with a rather simple Boolean (True/False) unit. 

As I write this section, the temperature outside is a sweltering 32 °C (36 with the humidex), so what better exposure unit to consider than "tropical nights", nights with a minimum temperature above 20 °C. We will limit our analysis to the summer months.

This code requires that your "Date" column is recognized as such by Python. This isn't always automatic, so you will likely need to ask **pandas** to convert the column to a `datetime` object. 

```{python, deco=list()}
tor.Date = pd.to_datetime(tor.Date)
```

Now let's start by adding a new column to our table called "TropNight", which will be a True/False value.

```{python, deco=list()}
tor['TropNight'] = ((tor.MinTemp > 20) & (tor.Date.dt.month.isin([6, 7, 8])))
print(tor.head())
```

Since our value is Boolean, we can use that column as an index. Let's double-check to make sure that we got the results that we were expecting.

```{python, deco=list()}
print(tor[tor.TropNight].head())
```

Now let's get an aggregate data set by grouping by the year. 

```{python, deco=list()}
tor_trop = tor[['Date', 'TropNight']].groupby(tor.Date.dt.year).sum()
print(tor_trop.head())
```

We can plot this easily. Note, this book is generated on a machine with no display, if you want to see the plot, run `plot.show()` or set the option `%matplotlib inline` if you are using Jupyter Notebook.

```{python, deco=list()}
tor_trop.plot()
```
```{python, include=FALSE}
plt.savefig('l1f1.png')
plt.clf()
```

```{r l1f1, echo=FALSE, fig.cap="Total summertime tropical nights at Toronto (1981\u20122010)."}
knitr::include_graphics("l1f1.png", dpi = NA)
```

The grouping operation has changed our table index to the years from 1981 to 2010. We want to keep this information in the table, so we can reset our index like this:

```{python, deco=list()}
tor_trop.reset_index(level = 0, inplace = True)
print(tor_trop.head())
```

Now let's make another plot, this time with a trendline. 

```{python, deco=list()}
plt.plot(tor_trop.Date, tor_trop.TropNight)
plt.plot(tor_trop.Date, np.polyval(np.polyfit(tor_trop.Date, tor_trop.TropNight, 1), tor_trop.Date))
plt.title("Total summertime Tropical Nights at Toronto (1981‒2010)")
plt.xlabel("Year")
plt.ylabel("No. of Tropical Nights")
```
```{python, include = FALSE}
plt.savefig('l1f2.png')
plt.clf()
```

```{r l1f2, echo=FALSE, fig.cap="Total summertime tropical nights at Toronto (1981\u20122010), with linear trend line."}
knitr::include_graphics("l1f2.png", dpi = NA)
```

Let's try for a slightly more complicated exposure unit: Winter heating degree days (HDDs). The HDDs represent the difference between the mean temperature and the base temperature of 18 °C. Since HDDs can't be negative, they are only calculated when the mean temperature is below 18 °C. They are used as an indirect measure of energy demand. 

We can apply an anonymous (lambda) function to our `MinTemp` column to capture the following pseudocode expression:

<center>`return 0 if the mean temperature was above 18, otherwise, return the difference between 18 and the mean temperature`</center>

```{python, deco=list()}
tor['HDD'] = tor.MeanTemp.apply(lambda x: 0 if x >= 18 else 18 - x)
```

We have one more challenge to overcome. A common mistake when performing seasonal analysis on the winter is to simply group December, January, and February by year. This is an easy logical jump to make. Remember, when we refer to winter, we mean the _continuous_ winter season that stretches from the December of the previous year to February of the current year. The easiest way to control for this is to add 1 to the year for any December. Winter 1981/82, for example will then appear with `'Year'` 1982 in the data frame. 

```{python, deco=list()}
tor['Year'] = tor.Date.apply(lambda x: x.year + 1 if x.month == 12 else x.year)
```

Now we can aggregate our heating degree days. Pay close attention to the code below. First, I use two conditional filters in the square brackets. The first drops the two winters that I know are incomplete: winter 1980/81 (which is missing December 1980), and winter 2010/2011, which is really just December 2010 here. A better solution for the first issue would be to download data including December 1980. The second condition filter to just our winter months, 12, 1, and 2. Next, I select only the two columns that are of interest, group them by `'Year'` and aggregate by `sum()`. Finally, I reset the index. 

```{python, deco=list()}
tor_hdd = tor[tor.Year.isin(range(1982, 2011)) & tor.Date.dt.month.isin([12, 1, 2])][['Year', 'HDD']].groupby('Year').sum().reset_index()
print(tor_hdd.head())
```

```{python, deco=list()}
plt.plot(tor_hdd.Year, tor_hdd.HDD)
plt.plot(tor_hdd.Year, np.polyval(np.polyfit(tor_hdd.Year, tor_hdd.HDD, 1), tor_hdd.Year))
plt.title("Winter HDD at Toronto (1981/82‒2009/10)")
plt.xlabel("Year")
plt.ylabel("Heating Degree Days  (HDD)")
```
```{python, include = FALSE}
plt.savefig('l1f3.png')
plt.clf()
```

```{r l1f3, echo=FALSE, fig.cap="Total wintertime heating degree days (HDD) at Toronto (1981\u20122010), with linear trend line."}
knitr::include_graphics("l1f3.png", dpi = NA)
```

Let's see if we can detect any trends in our baseline values. For convenience, I am going to create a function that will spit out the relevant values. You can run these commands directly, but this might save you time when you get to the exercises (Hint!).

```{python, deco=list()}
def test_trends(years, values):
    slope, intercept, r_value, p_value, std_err = stats.linregress(years, values)
    print("The regression coefficients are", np.round(slope, 3), "for the slope and",
          np.round(intercept, 1), "for the intercept\n")

    t_crit = stats.t.ppf(0.975, len(years) - 1)
    confidence_interval = t_crit * std_err
    print("The true value of the slope is then", np.round(slope, 3), "+/-",
          np.round(confidence_interval, 3),"\n")

    pearsons_corrcoef, p_corr = stats.pearsonr(years,  values)
    levels = [0.001, 0.01, 0.05, 0.1]
    lvl = [i for i in levels if p_corr < i]
    print("The correlation is", np.round(pearsons_corrcoef, 3), "with a p-value of",
          np.round(p_corr, 5), "(not significant)\n" if lvl == [] else
          "(significant at the " + str(min(lvl)) + " level)\n")

    print("The variance in", values.name, "explained by the linear trend is",
          "quantified by the R²: R² =",
          np.round(100 * pearsons_corrcoef**2, 3), '%.\n')
```


```{python, deco=list()}
test_trends(tor_trop.Date, tor_trop.TropNight)
```

```{python, deco=list()}
test_trends(tor_hdd.Year, tor_hdd.HDD)
```

## Exercises (what to submit)

```{block, type='rmdassignment'}
- You have been assigned an exposure unit and period. Write a brief description of the exposure unit, whether there were any missing or suspicious data, and how these data were treated. [2 marks] 
- Include the time series plots with fitted trend lines for your exposure unit and for the relevant temperature variable, e.g. `MeanTemp` for freezing degree days. [2 marks] 
- Include a table with the summary statistics for your exposure unit and temperature variable. [2 marks] 
- Read both of the "methods" sections above, for obtaining Canadian climate data. You will notice that we have chosen different dates at which to "append" the `Tor2` object to `Tor1` in each example. Repeat your analysis using the other merge date. Have your results changed? Briefly (one sentence is fine) discuss the selection of an appropriate merge date when working with separate data sets. [2 marks] 
- Be sure to clearly label your plots and table and include concise figure and table captions. [2 marks]
```
